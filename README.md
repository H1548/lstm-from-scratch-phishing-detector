# Phishing Detector using an LSTM Built From Scractch

This project consists of building a vanilla LSTM from scratch, both the forward and backward pass, to detect phishing emails. 
There is little use of frameworks to build out the LSTM, however to wrap data in tensors and to train the LSMT on multiple batch with the use of pytorch.
The loss function along with optimization and word embedings are also coded from scratch.

The phishing email dataset used to train this model, was sythentically generated by a data generation script found within this repo.

## Features
- LSTM that classifies Phishing and safe emails
- LSTM is built from complete scratch
- Loss function and adam optimizer built from scratch
- manual forward and backward pass

# Installation
## clone the repository 
```bash
git clone https://github.com/H1548/lstm-from-scratch-phishing-detector.git
cd lstm-from-scratch-phishing-detector 
```
## Install dependencies
<pre>pip install -r requirements.txt</pre>

# Usage

## Train Model

```bash
python train.py
```
## Evaluate model
```bash
python modeltest.py
```
## Prompt model
```bash
python prompter.py
```

# Results
Have not tested the model's performance, have only got it to work, it trains the loss score seems to go down in a stable way. 
Furthermore, I have prompted the model in a local jupyter notebook and seems to be acccurate. Future work on this project will be to rigorously evaluate this model. However, the main goal was to educate myself in builidng a deep-learning model from scratch using calculus for backprop etc.  

# Project Structure

```text
.
|-- Dataset/              # Folder containing train dataset and testing dataset
|-- Results/              # All the results after modeltest.py has run, goes into this folder 
|-- .gitignore            # ignores certain file types
|-- dataloader.py         # Script that loads training data
|-- LICENSE               # License for usage
|-- m.model               # SentencePiece Tokenizer
|-- m.vocab               # Vocabulary from sentencepiece tokenizer  
|-- model.py              # code for LSTM
|-- modeltest.py          # Code that evaluates LSTM, dumps confusion matrix and classifcaiton report into Results folder
|-- Prompter.py           # Script to prompt the LSTM model
|-- README.md             # Documentation
|-- requirements.txt      # Project Dependencies
|-- testdataloader.py     # loads test data
|-- train.py              # script trains the LSTM
|-- utils.py              # Utility functions
```

# Roadmap

The next steps of this project is to:
- Test and evaluate the LSTMs performance
- log results
- conduct hyperparameter tuning to improve model's performance 
- iterate this process till satisfied 